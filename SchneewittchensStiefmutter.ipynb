{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SchneewittchensStiefmutter.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Nc-b1Btxg3Sf"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNnd6Bt1tJ6puGGv6JUCB1v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sflin/SchneewittchensStiefmutter/blob/master/SchneewittchensStiefmutter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc-b1Btxg3Sf",
        "colab_type": "text"
      },
      "source": [
        "# **Schneewittchens Stiefmutter** - Ein Tool zum Generieren von Fragen aus Texten\n",
        "\n",
        "Dies ist ein Google Colab Notebook, das alle nötigen Informationen enthält um sich automatisch Fragen aus Texten zu generieren. Das Notebook ist so konzipiert, dass es auch ohne Programmierkenntnisse problemlos verwendbar ist.\n",
        "\n",
        "Bitte folgen Sie den Anweisungen in den Kästchen und führen Sie diese Schritt für Schritt **der Reihe nach aus**.\n",
        "\n",
        "> **Wichtig**: Ein Notebook besteht aus verschiedenen Code-Zellen (Kästchen). Um eine Zelle auszuführen, **klickt man zuerst in die Zelle *hinein*** und **dann auf das grau hinterlegte Dreieck** in der linken Spalte, so wie im  Screenshot: ![Dreieck](https://drive.google.com/uc?id=1AdQCZGnFTr4twrSd7xSYPICPELhcKXfi)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is a Google Colab Notebook containing all necessary information to generate questions out of German texts. The notebook was prepared in such a way that it should be executable also by those who are not familiar with programming. \n",
        "\n",
        "Please follow the specifications in the cells and **execute them step by step**.\n",
        "\n",
        "> **Important**: A notebook consists of different code-cells. In order to run a cell, **click first *into* the cell** and then **click the grey triangle** on the left of the cell (see screenshot above)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaHJVSg10yHI",
        "colab_type": "text"
      },
      "source": [
        "**Hilfe**\n",
        "\n",
        "Falls ein Fehler auftritt, überprüfen Sie bitte die folgenden Punkte:\n",
        "1. Haben Sie alle Kästchen **in der beschriebenen Reihenfolge** ausgeführt?\n",
        "2. Fehler beim Herunterladen der generierten Fragen: Bestätigen Sie, dass das Notebook mehrere Dateien herunterladen darf (es wird ein Pop-Up oder Balken oder eine entsprechende Meldung im Browser angezeigt). \n",
        "3. Versuchen Sie das Kästchen, in dem der Fehler auftritt, nochmals auszuführen (ins Kästchen klicken und CTRL + F10 drücken).\n",
        "3. Versuchen Sie das Tool mit dem Chrome-Browser auszuführen.\n",
        "4. Melden Sie sich unter selin.fabel@uzh.ch\n",
        "\n",
        "---\n",
        "\n",
        "**Troubleshooting**\n",
        "If an error occurs, please check the following points:\n",
        "1. Have you run all cells **in the order described**?\n",
        "2. Error while downloading the generated questions: confirm that the notebook is allowed to download multiple files (a pop-up or horizontal bar at the top or a corresponding message will be displayed in the browser) \n",
        "3. Try to re-run the cell where the error occurs (click in the box and hit CTRL + F10)\n",
        "3. Try to execute the tool with the Chrome-browser.\n",
        "4. Write an email to to selin.fabel@uzh.ch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GDux9pL06z-",
        "colab_type": "text"
      },
      "source": [
        "# Tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsJgDaXyc1H1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Spezifizieren Sie die folgende URL um Text von einer Webseite zu laden und führen Sie die Code-Zelle aus: { run: \"auto\" }\n",
        "#@markdown **Hinweis**: Die Extraktion wurde mit Texten im Format von Wikipedia-Artikeln implementiert und getestet. Für das Parsen von Non-Wikipedia-Artikel empfiehlt es sich, den Textfeld-Input oder den Dateiinput zu verwenden (s. nächsten Zellen).\n",
        "\n",
        "#@markdown Specify the following URL to load text from an existing website and run the cell:\\\n",
        "#@markdown **Hint**: The extraction was implemented and tested with texts in the format of Wikipedia articles. For parsing of non-Wikipedia articles it is recommended to use the text field input or file input (see cells below).\n",
        "URL = 'https://de.wikipedia.org/wiki/Emmy_von_Rhoden' #@param {type:\"string\"}\n",
        "content = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guPvKZn6F8Qw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ...oder führen Sie diese Zelle aus um Text aus einer Datei hochzuladen.\n",
        "#@markdown ...or run this code cell to upload text from a file. \n",
        "from google.colab import files\n",
        "import io\n",
        "content = files.upload()\n",
        "content = io.BytesIO(list(content.values())[0]).read().decode('UTF-8') \n",
        "URL = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzi0jaOO39nh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ...oder kopieren Sie ihren Text in dieses Feld. { run: \"auto\" }\n",
        "#@markdown ...or paste text in this field.\n",
        "\n",
        "content = \"\" #@param {type:\"string\"}\n",
        "URL = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou2Gcb8MTjwQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Falls es sich im Text um eine Person dreht, sollen Koreferenzen (z.B. \"sie\" oder \"er\") ersetzt werden? Bitte kreuzen Sie die Box \"replace_objects\" an, wählen das Geschlecht aus dem \"gender_dropdown\" aus und geben den Ersatz im Feld \"replacement\" an. Dann führen Sie diese Zelle aus. { run: \"auto\" }\n",
        "#@markdown If the text is about a person, should co-referent items (e.g. \"sie\" (she) or \"er\" (he)) be replaced? Please check the box \"replace_objects\", select the gender from the \"gender_dropdown\" and fill the \"replacement\". Then execute this cell.  \n",
        "replace_objects = True #@param {type:\"boolean\"}\n",
        "gender_dropdown = \"female\" #@param [\"male\", \"female\", \"neutral\"]\n",
        "replacement = 'Emmy von Rhoden' #@param {type:\"string\"}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylxGarft1qj2",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Sollen die Fragen danach heruntergeladen werden? { run: \"auto\" }\n",
        "#@markdown Would you like to download the generated questions?  \n",
        "download_questions = False #@param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPsB2WdcqtBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title -- { display-mode: \"form\" }\n",
        "#@markdown ## ![Start](https://drive.google.com/uc?id=1aUu3b7eGdXOb2-wB3TirOL0dDQQorLXz) &nbsp; Nur bei der **ersten** Ausführung (sonst weiter bei \"Re-Start\"-Zelle weiter unten): Zelle anwählen und CTRL+F10 drücken. \n",
        "\n",
        "#@markdown **First execution only** (otherwise see \"Re-Start\"-cell below): Select this cell. Then hit CTRL+F10."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir6XjHcdMLpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Installation von benötigten Modulen, Modell herunterladen (dauert einen Moment) { display-mode: \"form\" }\n",
        "#@markdown Install required packages, download model (this may take a while)\n",
        "!pip install dateparser\n",
        "!pip3 install duden\n",
        "!pip install ktrain==0.11.0\n",
        "!pip install -U textblob-de\n",
        "!sudo locale-gen de_DE.utf8\n",
        "!update-locale LANG=de_DE.UTF-8\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.bin.gz\n",
        "!gunzip -k cc.de.300.bin.gz\n",
        "!wget https://www.dropbox.com/s/fqcfqxuq1zjvd6x/predictor-crf.preproc?dl=0 -O predictor-crf.preproc\n",
        "!wget https://www.dropbox.com/s/hxkf4xx8d7v01hn/predictor-crf?dl=0 -O predictor-crf\n",
        "!wget https://www.dropbox.com/s/q52fx19dam6uujz/df-types.parquet.gzip?dl=0 -O df-types.parquet.gzip\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrKJfyIOZ3RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Imports tätigen { display-mode: \"form\" }\n",
        "#@markdown Organize imports\n",
        "%tensorflow_version 2.x\n",
        "import dateparser\n",
        "import datetime\n",
        "import duden\n",
        "import gensim\n",
        "import itertools\n",
        "import ktrain\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import spacy\n",
        "import spacy.cli\n",
        "import tensorflow as tf\n",
        "from bs4 import BeautifulSoup\n",
        "from dateutil.parser import parse\n",
        "from dateutil.parser import parserinfo\n",
        "from gensim.models.wrappers import FastText\n",
        "from google.colab import files\n",
        "from ktrain import text\n",
        "from textblob_de.packages import pattern_de as patt\n",
        "spacy.cli.download(\"de_core_news_sm\")\n",
        "nlp = spacy.load(\"de_core_news_sm\")\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfpVGiXfB1lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Daten und Modell initialisieren (dauert einen Moment) { display-mode: \"form\" }\n",
        "#@markdown Load types and models (this may take while)\n",
        "df = pd.read_parquet('df-types.parquet.gzip')\n",
        "df2 = pd.DataFrame({'label':['sich','mich','dich','uns','sie'], 'type':['Präposition','Präposition','Präposition','Präposition','Präposition',]})\n",
        "df = df.append(df2)\n",
        "model = FastText.load_fasttext_format('cc.de.300.bin')\n",
        "predictor = ktrain.load_predictor('predictor-crf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iWdw0rcTtKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "def make_prediction(content):\n",
        "  \"\"\"\n",
        "  Finds triplets in content-string.\n",
        "    :param content: str, string to find triplets in\n",
        "    :return predictions: array_like, list of triplets with content\n",
        "      [{'OBJ':[],'REL':[],'VAL':[], 'CONTEXT':[content]}] \n",
        "  \"\"\"\n",
        "  try:\n",
        "    prediction = predictor.predict(content)\n",
        "  except ValueError:\n",
        "    print('Value error for ' + str(content))\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    print(\"Something else went wrong: \" + str(e))\n",
        "    return None\n",
        "  predicted_triplet = {'OBJ':[None],'REL':[None],'VAL':[None]}\n",
        "  triplet_found = False\n",
        "  index_range = list(range(len(prediction)))\n",
        "  for i in index_range:\n",
        "    if prediction[i][1].endswith('-obj'):\n",
        "      objs = predicted_triplet['OBJ']\n",
        "      tmp = prediction[i][0]\n",
        "      look_for_triplets = True\n",
        "      while look_for_triplets and i < index_range[-1]:\n",
        "        i += 1\n",
        "        if prediction[i][1] == 'I-obj':\n",
        "          tmp = tmp + ' ' + prediction[i][0]\n",
        "          index_range.remove(i)\n",
        "        else:\n",
        "          look_for_triplets = False\n",
        "      objs.append(tmp)\n",
        "      predicted_triplet['OBJ'] = objs\n",
        "      triplet_found = True\n",
        "    elif prediction[i][1].endswith('-val'):\n",
        "      val = predicted_triplet['VAL']\n",
        "      tmp = prediction[i][0]\n",
        "      look_for_triplets = True\n",
        "      while look_for_triplets and i < index_range[-1]:\n",
        "        i += 1\n",
        "        if prediction[i][1] == 'I-val':\n",
        "          tmp = tmp + ' ' + prediction[i][0]\n",
        "          index_range.remove(i)\n",
        "        else:\n",
        "          look_for_triplets = False\n",
        "      val.append(tmp)\n",
        "      predicted_triplet['VAL'] = val\n",
        "      triplet_found = True\n",
        "    elif prediction[i][1].endswith('-rel'):\n",
        "      rel = predicted_triplet['REL']\n",
        "      tmp = prediction[i][0]\n",
        "      look_for_triplets = True\n",
        "      while look_for_triplets and i < index_range[-1]:\n",
        "        i += 1\n",
        "        if prediction[i][1] == 'I-rel':\n",
        "          tmp = tmp + ' ' + prediction[i][0]\n",
        "          index_range.remove(i)\n",
        "        else:\n",
        "          look_for_triplets = False\n",
        "      rel.append(tmp)\n",
        "      predicted_triplet['REL'] = rel\n",
        "      triplet_found = True\n",
        "  if triplet_found:\n",
        "    obj = predicted_triplet['OBJ'][1:] if len(predicted_triplet['OBJ']) > 1 else [None]\n",
        "    rel = predicted_triplet['REL'][1:] if len(predicted_triplet['REL']) > 1 else [None]\n",
        "    val = predicted_triplet['VAL'][1:] if len(predicted_triplet['VAL']) > 1 else [None]\n",
        "    permutations = list(itertools.product(*[obj, rel, val]))\n",
        "    predictions = [{'OBJ':[p[0]],'REL':[p[1]],'VAL':[p[2]], 'CONTEXT':[content]} for p in permutations]    \n",
        "    return predictions\n",
        "  else:\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oriyI9I7alMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "def get_baseline(content=None, url = None):\n",
        "  \"\"\" Finds triplets, either in given string or in article on website (URL).\n",
        "  :param content: str, optional, a text\n",
        "  :param url: str, optional, an URL\n",
        "  :return result: array_like, list of dictionary containing triplets\n",
        "  \"\"\"\n",
        "  \n",
        "  if url:\n",
        "    url = url + \"?action=render\"\n",
        "    response = requests.get(url)\n",
        "    html = BeautifulSoup(response.text, 'html.parser')\n",
        "    paragraphs = html.select(\"p\")\n",
        "    content = \"\".join([para.text for para in paragraphs])\n",
        "  content = content.replace(\";\", \",\")\n",
        "  content = content.replace(\" |\", \",\")\n",
        "  content = re.sub(r\"(\\s+|\\n)\", \" \", content)\n",
        "  content = re.sub(r\"[\\'`\\\"']|(\\[[^]]*\\])|(,,)|(\\( .*\\?\\/i\\)\\s)\", \"\",content)\n",
        "  content = content.replace('*', 'geboren am')\n",
        "  content = content.replace('†', 'gestorben am')\n",
        "  content = content.replace('•', '')\n",
        "  nlp = spacy.load(\"de_core_news_sm\")\n",
        "  doc = nlp(content)\n",
        "  sentences = list(doc.sents)\n",
        "  result = []\n",
        "  triplets = []\n",
        "  for i in range(1, len(sentences) -1):\n",
        "    search_text = sentences[i-1].text + ' ' + sentences[i].text + ' ' + sentences[i+1].text\n",
        "    prediction = find_triplets(sentences[i-1:i+2])\n",
        "    for pred in prediction:\n",
        "      if pred['OBJ'] and pred['REL'] and pred['VAL'] and (pred['OBJ'], pred['REL'], pred['VAL']) not in triplets:\n",
        "        print(pred)\n",
        "        result.append(pred)\n",
        "        triplets.append((pred['OBJ'], pred['REL'], pred['VAL']))\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pn0bTTFPtDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "def make_prediction_with_url(content=None, url=None):\n",
        "  \"\"\" Wrapper object to apply ktrain-predictor to text. Either in given string \n",
        "    or in article on website (URL).\n",
        "  :param content: str, optional, a text\n",
        "  :param url: str, optional, an URL to retrieve the article from\n",
        "  :param predictor: ktrain-predictor object\n",
        "  :return result: array_like, list of dictionary containing triplets\n",
        "  \"\"\"\n",
        "  \n",
        "  if url:\n",
        "    url = url + \"?action=render\"\n",
        "    response = requests.get(url)\n",
        "    html = BeautifulSoup(response.text, 'html.parser')\n",
        "    paragraphs = html.select(\"p\")\n",
        "    content = \"\".join([para.text for para in paragraphs])\n",
        "  content = content.replace(\";\", \",\")\n",
        "  content = content.replace(\" |\", \",\")\n",
        "  content = re.sub(r\"(\\s+|\\n)\", \" \", content)\n",
        "  content = re.sub(r\"[\\'`\\\"']|(\\[[^]]*\\])|(,,)|(\\( .*\\?\\/i\\)\\s)\", \"\",content)\n",
        "  content = content.replace('(', '( ')\n",
        "  content = content.replace(')', ' )')\n",
        "  content = content.replace('„', '')\n",
        "  content = content.replace('”', '')\n",
        "  content = content.replace('“', '')\n",
        "  content = content.replace('‘', '')\n",
        "  content = re.sub(r\"\\d-\\d\", \"\\d - \\d\", content)\n",
        "  content = re.sub(r\"\\d–\\d\", \"\\d – \\d\", content)\n",
        "  content = content.replace('•', '')\n",
        "  nlp = spacy.load(\"de_core_news_sm\")\n",
        "  doc = nlp(content)\n",
        "  sentences = list(doc.sents)\n",
        "  result = []\n",
        "  triplets = []\n",
        "  for i in range(1, len(sentences) -1):\n",
        "    search_text = sentences[i-1].text + ' ' + sentences[i].text + ' ' + sentences[i+1].text\n",
        "    predictions = make_prediction(search_text)\n",
        "    if predictions:\n",
        "      for p in predictions:\n",
        "        for s in [sentences[i-1], sentences[i], sentences[i+1]]:\n",
        "          prediction = resolve_prediction(s, p)\n",
        "          if prediction and (prediction['OBJ'], prediction['REL'], prediction['VAL']) not in triplets:\n",
        "            result.append(prediction)\n",
        "            triplets.append((prediction['OBJ'], prediction['REL'], prediction['VAL']))\n",
        "            print(prediction)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRbNRGcaRXIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "def resolve_prediction(sentence, prediction):\n",
        "  \"\"\" Helper method to fill incomplete triplets. \n",
        "  :param sentence: spacy-token string\n",
        "  :param prediction: dict, an incomplete triplet\n",
        "  :return prediction: dict, a complete triplet with object, relation, value\n",
        "  \"\"\"\n",
        "\n",
        "  rel = [None]\n",
        "  val = [None]\n",
        "  obj = [None]\n",
        "  # if nothing is present, do not make any prediction!\n",
        "  if not prediction:\n",
        "    return None\n",
        "  # everything already present\n",
        "  if prediction['OBJ']!=[None] and prediction['REL']!=[None] and prediction['VAL']!=[None]:\n",
        "    return prediction\n",
        "  #print(prediction['OBJ'], prediction['REL'], prediction['VAL'], sentence)\n",
        "  sentence = nlp(sentence.text)\n",
        "  # CASE 1: obj and rel are present\n",
        "  if prediction['OBJ']!=[None] and prediction['REL']!=[None]:\n",
        "    rel = prediction['REL'][0].split(' ')[0]\n",
        "    val = [token.text for token in sentence if (token.dep_ == 'pd' and token.head.text == rel)] \n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'oc' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'oa' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'da' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'ag' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'nk' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      return None\n",
        "    prediction['VAL'] = [' '.join([v for v in val])]\n",
        "  # CASE 2: obj and val are present\n",
        "  elif prediction['OBJ']!=[None] and prediction['VAL']!=[None]:\n",
        "    obj_item = prediction['OBJ'][0].split(' ')[-1]\n",
        "    rel = [token.head.text for token in sentence if token.text == obj_item]\n",
        "    if not rel:\n",
        "      return None\n",
        "    sent_head = get_head(rel[0], sentence)\n",
        "    prediction['REL'] = [sent_head]\n",
        "  # CASE 3: rel and val are present\n",
        "  elif prediction['REL']!=[None] and prediction['VAL']!=[None]:\n",
        "    rel = prediction['REL'][0].split(' ')[0]\n",
        "    obj = [token.text for token in sentence if (token.dep_ == 'sb' and token.head.text == rel[0])]\n",
        "    if not obj:\n",
        "      return None\n",
        "    prediction['OBJ'] = obj\n",
        "  # CASE 4: only obj is present\n",
        "  elif prediction['OBJ']!=[None]:\n",
        "    obj_item = prediction['OBJ'][0].split(' ')[-1]\n",
        "    rel = [token.head.text for token in sentence if token.text == obj_item]\n",
        "    if rel:\n",
        "      sent_head = get_head(rel[0], sentence)\n",
        "      #[print(token, token.dep_, token.head.text) for token in sentence]\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'pd' and token.head.text == rel[0])] \n",
        "      if not val:\n",
        "        val = [token.text for token in sentence if (token.dep_ == 'oc' and token.head.text == rel[0])]\n",
        "      if not val:\n",
        "        val = [token.text for token in sentence if (token.dep_ == 'oa' and token.head.text == rel[0])]\n",
        "      if not val:\n",
        "        val = [token.text for token in sentence if (token.dep_ == 'da' and token.head.text == rel[0])]\n",
        "      if not val:\n",
        "        val = [token.text for token in sentence if (token.dep_ == 'ag' and token.head.text == rel[0])]\n",
        "      if not val:\n",
        "        val = [token.text for token in sentence if (token.dep_ == 'nk' and token.head.text == rel[0])]\n",
        "      if not val:\n",
        "        return None\n",
        "      prediction['REL'] = [sent_head]\n",
        "      prediction['VAL'] = [' '.join([v for v in val])]\n",
        "  # CASE 5: only rel is present\n",
        "  elif prediction['REL']!=[None]:\n",
        "    rel = prediction['REL'][0].split(' ')[0]\n",
        "    obj = [token.text for token in sentence if (token.dep_ == 'sb' and token.head.text == rel)]\n",
        "    if not obj:\n",
        "      return None\n",
        "    val = [token.text for token in sentence if (token.dep_ == 'pd' and token.head.text == rel)] \n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'oc' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'oa' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'da' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'ag' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      val = [token.text for token in sentence if (token.dep_ == 'nk' and token.head.text == rel)]\n",
        "    if not val:\n",
        "      return None\n",
        "    prediction['VAL'] = [' '.join([v for v in val])]\n",
        "    prediction['OBJ'] = obj\n",
        "  # CASE 6: only val is present\n",
        "  elif prediction['VAL']!=[None]:\n",
        "    for nc in sentence.noun_chunks:\n",
        "      sent_head = get_head(nc.root.head.text, sentence)\n",
        "      prediction['REL'] = [sent_head]\n",
        "      if nc.root.dep_ == 'sb':\n",
        "        prediction['OBJ'] = [nc.text]\n",
        "        break\n",
        "  if not prediction['OBJ'] or not prediction['REL'] or not prediction['VAL'] or prediction['OBJ'] == [None] or prediction['REL'] == [None] or prediction['VAL']==[None]:\n",
        "    return None\n",
        "  else:\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHu7dBwIbWb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title  { display-mode: \"form\" }\n",
        "def get_head(head_obj, sentence):\n",
        "  \"\"\" Helper method to retrieve the full head of a given object.\n",
        "  :param head_obj: a head candidate\n",
        "  :param sentence: spacy-token string\n",
        "  :return final_head: str, the full head\n",
        "  \"\"\"\n",
        "  final_head = head_obj\n",
        "  for token in sentence:\n",
        "    if token.text != head_obj and token.head.text == head_obj and token.tag_ in ['PTKVZ', 'ADJD']:\n",
        "      final_head = final_head + ' ' + token.text.lower()\n",
        "  return final_head\n",
        "\n",
        "def find_triplets(sentences):\n",
        "  \"\"\" Helper method to find triplets in given sentences. \n",
        "  :param sentences: array_like, list of spacy-sentences \n",
        "  :return values: array_like, list of found triplets in input-sentences\n",
        "  \"\"\"\n",
        "  predictions = {}\n",
        "  context = ' '.join([sent.text for sent in sentences])\n",
        "  for sent in sentences:\n",
        "    sent = nlp(sent.text)\n",
        "    for nc in sent.noun_chunks:\n",
        "      sent_head = get_head(nc.root.head.text, sent)\n",
        "      if sent_head not in predictions:\n",
        "        predictions[sent_head] = {'OBJ': None, 'REL': [sent_head], 'VAL': None, 'CONTEXT': [context]}\n",
        "      if nc.root.dep_ == 'sb':\n",
        "        tmp = predictions[sent_head]\n",
        "        tmp['OBJ'] = [nc.text]\n",
        "        predictions[sent_head] = tmp\n",
        "      elif not predictions[sent_head]['VAL'] and nc.root.dep_ == 'pd': \n",
        "        tmp = predictions[sent_head]\n",
        "        tmp['VAL'] = [nc.text]\n",
        "        predictions[sent_head] = tmp\n",
        "      elif not predictions[sent_head]['VAL'] and nc.root.dep_ == 'oa': \n",
        "        tmp = predictions[sent_head]\n",
        "        tmp['VAL'] = [nc.text]\n",
        "        predictions[sent_head] = tmp\n",
        "      elif not predictions[sent_head]['VAL'] and nc.root.dep_ == 'da': \n",
        "        tmp = predictions[sent_head]\n",
        "        tmp['VAL'] = [nc.text]\n",
        "        predictions[sent_head] = tmp\n",
        "      elif not predictions[sent_head]['VAL'] and nc.root.dep_ == 'ag': \n",
        "        tmp = predictions[sent_head]\n",
        "        tmp['VAL'] = [nc.text]\n",
        "        predictions[sent_head] = tmp\n",
        "      elif not predictions[sent_head]['VAL'] and nc.root.dep_ == 'nk':\n",
        "        tmp = predictions[sent_head]\n",
        "        tmp['VAL'] = [nc.text]\n",
        "        predictions[sent_head] = tmp\n",
        "  values = list(predictions.values())\n",
        "  return values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28n5sJ8roqhN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title --\n",
        "#@markdown ## ![Re-Start](https://drive.google.com/uc?id=111kJPmPWeqSrNxQkE252dQNShz0pM7VG)Bei jeder weiteren Ausführung: Zelle anwählen und CTRL+F10. { display-mode: \"form\" }\n",
        "#@markdown Every other execution: Select this cell. Then hit CTRL+F10."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KSurzeliTWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Triplets extrahieren (Baseline und mit Modell) { display-mode: \"form\" }\n",
        "#@markdown Extract triplets (baseline and model)\n",
        "if URL:\n",
        "  baseline_predictions = get_baseline(url=URL)\n",
        "  predictions = make_prediction_with_url(url=URL)\n",
        "  clear_output()\n",
        "elif content and len(content) > 1:\n",
        "  baseline_predictions = get_baseline(content)\n",
        "  predictions = make_prediction_with_url(content)\n",
        "  clear_output()\n",
        "else:\n",
        "  print(\"Bitte spezifieren Sie eine URL oder laden Sie einen Text hoch!\\n\")\n",
        "  print(\"Please specify an URL or upload a text!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ8wDzS0FXJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "def replace(predictions, replacement, object_type='neutral'):\n",
        "  \"\"\" Method that replaces \n",
        "  :param predictions: dict, triplets\n",
        "  :param replacement: str\n",
        "  :param object_type: str, indicates gender of object, default='neutral'\n",
        "  \"\"\"\n",
        "  for pred in predictions:\n",
        "    tmp = pred['OBJ']\n",
        "    if object_type == 'male':\n",
        "      splits = replacement.split(' ')\n",
        "      to_replace = [splits[-1], 'er', 'Er']\n",
        "      tmp = [replacement if x in to_replace else x for x in tmp]\n",
        "      to_replace = ['sein', 'seine', 'Sein', 'Seine']\n",
        "      tmp = [replacement + 's' if x in to_replace else x for x in tmp]\n",
        "    elif object_type == 'female':\n",
        "      splits = replacement.split(' ')\n",
        "      to_replace = [splits[-1], 'sie', 'Sie', 'ihr']\n",
        "      tmp = [replacement if x in to_replace else x for x in tmp]\n",
        "      to_replace = ['ihr', 'ihre', 'Ihr', 'Ihre']\n",
        "      tmp = [replacement + 's' if x in to_replace else x for x in tmp]\n",
        "    else:\n",
        "      to_replace = ['es', 'Es', 'er', 'Er']\n",
        "      tmp = [replacement if x in to_replace else x for x in tmp]\n",
        "    pred['OBJ'] = tmp\n",
        "    rel = pred['REL']\n",
        "    rel = ['geboren' if x == '*' else x for x in rel]\n",
        "    rel = ['gestorben' if x == '†' else x for x in rel]\n",
        "    pred['REL'] = rel\n",
        "  return predictions\n",
        "\n",
        "def filter_triplets(predictions):\n",
        "  \"\"\" Filter out the bad triplets according to their distance to the median.\n",
        "  :param predictions: array_like, list of triplets-dict\n",
        "  :return result: array_like, filtered triplets-dict\n",
        "  \"\"\"\n",
        "  max_distance = 0.0035\n",
        "  median=np.array([0.00080595, 0.00218227, 0.00070459])\n",
        "  result = []\n",
        "  for pred in predictions:\n",
        "    try:\n",
        "      x = np.mean(model[pred['OBJ'][0].replace(' ','')])\n",
        "      y = np.mean(model[pred['REL'][0].replace(' ','')])\n",
        "      z = np.mean(model[pred['VAL'][0].replace(' ','')])\n",
        "      vec = np.array([x, y, z])\n",
        "      distance = np.linalg.norm(median - vec)\n",
        "      if distance <= max_distance:\n",
        "        result.append(pred)\n",
        "    except (Exception) as e:\n",
        "      print(str(e))\n",
        "      continue\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kph5hd_da2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Ersetzen von koreferenten Objekten (falls gewünscht) und entfernen von \"schlechten\" Triplets { display-mode: \"form\" }\n",
        "#@markdown If desired, replace co-referent objects and remove \"bad\" triplets\n",
        "if 'replace_objects' in globals() and replace_objects:\n",
        "  baseline_predictions = replace(baseline_predictions, replacement, object_type = gender_dropdown)\n",
        "  predictions = replace(predictions, replacement, object_type = gender_dropdown)\n",
        "baseline_predictions = filter_triplets(baseline_predictions)\n",
        "predictions = filter_triplets(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx8QFrSBCIS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "class CustomParserInfo(parserinfo):\n",
        "    MONTHS = [(\"Januar\"), (\"Februar\", \"Feb\"), (\"März\", \"Mär\"), (\"April\", \"Apr\"), (\"Mai\", \"Mai\"), \n",
        "              (\"Juni\", \"Jun\"), (\"Juli\", \"Jul\"), (\"August\", \"Aug\"), (\"September\", \"Sep\"), \n",
        "              (\"Oktober\", \"Okt\"), (\"November\", \"Nov\"), (\"Dezember\", \"Dez\")]\n",
        "\n",
        "def is_date(label, fuzzy=False):\n",
        "    \"\"\"\n",
        "    Return whether the string can be interpreted as a date.\n",
        "    :param label: str, string to check for date\n",
        "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
        "    :return: bool, whether string is a date\n",
        "    \"\"\"\n",
        "    try: \n",
        "        parse(label, fuzzy=fuzzy, parserinfo=CustomParserInfo())\n",
        "        return True\n",
        "\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def lookup_category(label):\n",
        "  \"\"\"Method to categorize the given label. \n",
        "\n",
        "  :param label: str, the string to categorize\n",
        "  :return: array_like;\n",
        "    ['Zeitpunkt'] if date\n",
        "    ['Zahl'] if digit\n",
        "    [list of types] if label exists in types-table (types data frame) \n",
        "    [list of types] if one of the 20 most similar labels exists in types-table \n",
        "    ['Ding'] if nothing was found  \"\"\"\n",
        "    \n",
        "  is_digit = re.match('(^\\d*$|^\\d*\\.\\d*$)', label)\n",
        "  if not is_digit and is_date(label):\n",
        "    return ['Zeitpunkt']\n",
        "  elif is_digit:\n",
        "    return ['Zahl']\n",
        "  if label in df['label'].values:\n",
        "    types = df.loc[df['label'] == label, 'type'].values\n",
        "    return list(set(types))\n",
        "  else:\n",
        "    try:\n",
        "      lookup = model.wv.most_similar(positive=[label], topn=20)\n",
        "      for x in lookup:\n",
        "        if x[0] in df['label'].values:\n",
        "          types = df.loc[df['label'] == x[0], 'type'].values\n",
        "          return list(set(types))\n",
        "      return ['Ding']\n",
        "    except:\n",
        "      return ['Ding']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLV_4gT81Ke_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "auxiliary_dict = {'geboren':'wurde ','gestorben':'ist ','geschrieben':'wurde/hat ','gegründet':'wurde/hat ', 'getauft':'wurde/hat '}\n",
        "gap = '_____________'\n",
        "mc = ['A: ', 'B: ', 'C: ', 'D: ']\n",
        "\n",
        "def upper_first(s):\n",
        "    \"\"\"\n",
        "    Return a copy of the string s with its first character\n",
        "    capitalized.\n",
        "    :param s: str\n",
        "    :return str:\n",
        "    \"\"\"\n",
        "    return s[0].upper() + s[1:]\n",
        "\n",
        "def get_equivalents(pred, obj_cat, val_cat):\n",
        "  \"\"\"Retrieves the three most similar objects and values based on its type(s).\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :return: tuple, tuple containing object-replacements and value-replacements\"\"\"\n",
        "  \n",
        "  if np.where(obj_cat == 'Mensch') and len(obj_cat)>1:\n",
        "    np.delete(obj_cat, np.where(obj_cat == 'Mensch'))\n",
        "  if np.where(val_cat == 'Mensch') and len(val_cat)>1:\n",
        "    np.delete(val_cat, np.where(val_cat == 'Mensch'))\n",
        "  if 'Mensch' in obj_cat:\n",
        "    obj_eq = list(set(df.loc[(df['type'] == 'Mensch') & (df['label'] != pred['OBJ'][0]), 'label'].values))\n",
        "    obj_eq = random.sample(obj_eq, 3)\n",
        "  elif 'Zeitpunkt' in obj_cat:\n",
        "    prefix = 'am ' if 'am ' in pred['OBJ'][0] else ''\n",
        "    base = dateparser.parse(pred['OBJ'][0].replace('am ', ''), date_formats=['%d.%m.%Y'])\n",
        "    pred['OBJ'] = [prefix + base.strftime(\"%d.%m.%Y\")]\n",
        "    date_list = [base + datetime.timedelta(days=x) for x in [random.randrange(-100000, 100000, 1), random.randrange(-10000, 10000, 1), random.randrange(-100, 100, 1)]]\n",
        "    obj_eq = [prefix + date.strftime(\"%d.%m.%Y\") for date in date_list]\n",
        "  elif 'Zahl' in obj_cat:\n",
        "    base = float(pred['OBJ'][0]) if '.' in pred['OBJ'][0] else int(pred['OBJ'][0])\n",
        "    obj_eq = [str(base + x) for x in [random.randrange(-1000, 1000, 1), random.randrange(-100, 100, 1), random.randrange(-10, 10, 1)]]\n",
        "  else:\n",
        "    obj_equivalents = [df.loc[df['type'] == oc, 'label'].values for oc in obj_cat]\n",
        "    obj_equivalents = [item for sublist in obj_equivalents for item in sublist]\n",
        "    obj_freq = {} \n",
        "    for item in obj_equivalents: \n",
        "      if item != pred['OBJ'][0]:\n",
        "        obj_freq[item] = obj_equivalents.count(item) \n",
        "    obj_eq = sorted(obj_freq, key=obj_freq.get, reverse = True)\n",
        "  if 'Mensch' in val_cat:\n",
        "    val_eq = list(set(df.loc[(df['type'] == 'Mensch') & (df['label'] != pred['VAL'][0]), 'label'].values))\n",
        "    val_eq = random.sample(obj_eq, 3)\n",
        "  elif 'Zeitpunkt' in val_cat:\n",
        "    prefix = 'am ' if 'am ' in pred['VAL'][0] else ''\n",
        "    base = dateparser.parse(pred['VAL'][0].replace('am ', ''), date_formats=['%d.%m.%Y'])\n",
        "    pred['VAL'] = [prefix + base.strftime(\"%d.%m.%Y\")]\n",
        "    date_list = [base + datetime.timedelta(days=x) for x in [random.randrange(-100000, 100000, 1), random.randrange(-10000, 10000, 1), random.randrange(-100, 100, 1)]]\n",
        "    val_eq = [prefix + date.strftime(\"%d.%m.%Y\")for date in date_list]\n",
        "  elif 'Zahl' in val_cat:\n",
        "    base = float(pred['VAL'][0]) if '.' in pred['VAL'][0] else int(pred['VAL'][0])\n",
        "    val_eq = [str(base + x) for x in [random.randrange(-1000, 1000, 1), random.randrange(-100, 100, 1), random.randrange(-10, 10, 1)]]\n",
        "  else:\n",
        "    val_equivalents = [df.loc[df['type'] == vc, 'label'].values for vc in val_cat]\n",
        "    val_equivalents = [item for sublist in val_equivalents for item in sublist]\n",
        "    val_freq = {}\n",
        "    for item in val_equivalents: \n",
        "      if item != pred['VAL'][0]:\n",
        "        val_freq[item] = val_equivalents.count(item)\n",
        "    val_eq = sorted(val_freq, key=val_freq.get, reverse = True)\n",
        "  return (obj_eq[:3], val_eq[:3])\n",
        "\n",
        "def apply_rule1_extended(pred, rel, obj_cat, val_cat):\n",
        "  \"\"\"\n",
        "  #1 <Object> hat ein(e/en) <Relation (NN/NE)> von <Value (Number)>.\n",
        "    --> Mount Everest hat eine Höhe von 8848.\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :return true_stmt: str, statement which is true\n",
        "  :return false_stmt1: str, statement with a wrong object\n",
        "  :return false_stmt2: str, statement with a wrong value\n",
        "  :return gap_obj: str, statement with object blanked out\n",
        "  :return gap_val: str, statement with value blanked out\n",
        "  :return mc_obj: array_like, list of possible object-replacements\n",
        "  :return mc_val: array_like, list of possible value-replacements\n",
        "  \"\"\"\n",
        "  equivalents = get_equivalents(pred, obj_cat, val_cat)\n",
        "  obj_description = ' (' + '/'.join([word for word in obj_cat]) + ') ' if 'Ding' not in obj_cat else ''\n",
        "  val_description = ' (' + '/'.join([word for word in val_cat]) + ') ' if 'Ding' not in obj_cat else ''\n",
        "  noun = [token.text for token in rel if token.tag_ == 'NN' or token.tag_ == 'NE'][0]\n",
        "  gender = lookup_gender(noun)\n",
        "  suffixes = {'m':'en ', 'f':'e ', 'n':' ', 'UNK':'/e(n) '}\n",
        "\n",
        "  true_stmt = upper_first(pred['OBJ'][0]) + ' hat ein' + suffixes[gender] + rel.text + ' von ' + pred['VAL'][0] + '.'\n",
        "  false_stmt1 = upper_first(equivalents[0][0]) + ' hat ein' + suffixes[gender] + rel.text + ' von ' + pred['VAL'][0] + '.' if equivalents[0] else None\n",
        "  false_stmt2 = upper_first(pred['OBJ'][0]) + ' hat ein' + suffixes[gender] + rel.text + ' von ' + equivalents[1][0] + '.' if equivalents[1] else None\n",
        "  gap_obj = gap + obj_description + ' hat ein' + suffixes[gender] + rel.text + ' von ' + pred['VAL'][0] + '.'\n",
        "  gap_val = upper_first(pred['OBJ'][0]) + ' hat ein' + suffixes[gender] + rel.text + ' von ' + gap + val_description + '.'\n",
        "  mc_obj = equivalents[0] + pred['OBJ'] if equivalents[0] else []\n",
        "  mc_val = equivalents[1] + pred['VAL'] if equivalents[1] else []\n",
        "  random.shuffle(mc_obj)\n",
        "  random.shuffle(mc_val)\n",
        "  mc_obj = ' '.join([mc[i] + mc_obj[i] for i in range(len(mc_obj))])\n",
        "  mc_val = ' '.join([mc[i] + mc_val[i] for i in range(len(mc_val))])\n",
        "  return (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val)\n",
        "\n",
        "def apply_rule2_extended(pred, rel, obj_cat, val_cat, is_template_a):\n",
        "  \"\"\"\n",
        "  #2a <Object> ist <Relation (NN/NE)> <Relation (APPR/APPRART/PTKVZ)> <Value>.\n",
        "\t  --> Christopher Douglas Adams ist (der) Vater von Douglas Adams.\n",
        "  #2b <Object> hat als <Relation (NN/NE)> <Value>.\n",
        "\t  --> \"Eine kleine Nachtmusik\" hat als Komponist Wolfgang Amadeus Mozart.\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :param is_template_a: bool\n",
        "  :return true_stmt: str, statement which is true\n",
        "  :return false_stmt1: str, statement with a wrong object\n",
        "  :return false_stmt2: str, statement with a wrong value\n",
        "  :return gap_obj: str, statement with object blanked out\n",
        "  :return gap_val: str, statement with value blanked out\n",
        "  :return mc_obj: array_like, list of possible object-replacements\n",
        "  :return mc_val: array_like, list of possible value-replacements\n",
        "  \"\"\"\n",
        "  equivalents = get_equivalents(pred, obj_cat, val_cat)\n",
        "  obj_description = ' (' + '/'.join([word for word in obj_cat[1:]]) + ') ' if len(obj_cat) > 1 else ''\n",
        "  val_description = ' (' + '/'.join([word for word in val_cat[1:]]) + ') ' if len(val_cat) > 1 else ''\n",
        "  if is_template_a:\n",
        "    rel_head = ' '.join([token.text for token in rel if token.tag_ == 'NN' or token.tag_ == 'NE'])\n",
        "    rel_head = rel_head + ' ' if len(rel_head) > 0 else ''\n",
        "    rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'PTKVZ' or token.tag_=='APPR' or token.tag_=='APPRART'])\n",
        "    \n",
        "    true_stmt = upper_first(pred['OBJ'][0]) + ' ist ' + rel_head + rel_tail + ' ' + pred['VAL'][0] + '.'\n",
        "    false_stmt1 = upper_first(equivalents[0][0]) + ' ist ' + rel_head + rel_tail + ' ' + pred['VAL'][0] + '.' if equivalents[0] else None\n",
        "    false_stmt2 = upper_first(pred['OBJ'][0]) + ' ist ' + rel_head + rel_tail + ' ' + equivalents[1][0] + '.' if equivalents[1] else None\n",
        "    gap_obj = gap + obj_description + ' ist ' + rel_head + rel_tail + ' ' + pred['VAL'][0] + '.'\n",
        "    gap_val = upper_first(pred['OBJ'][0]) + ' ist ' + rel_head + rel_tail + ' ' + gap + val_description + '.'\n",
        "  else:\n",
        "    true_stmt = upper_first(pred['OBJ'][0]) + ' hat als ' + rel.text + ' ' + pred['VAL'][0] + '.'\n",
        "    false_stmt1 = upper_first(equivalents[0][0]) + ' hat als ' + rel.text + ' ' + pred['VAL'][0] + '.' if equivalents[0] else None\n",
        "    false_stmt2 = upper_first(pred['OBJ'][0]) + ' hat als ' + rel.text + ' ' + equivalents[1][0] + '.' if equivalents[1] else None\n",
        "    gap_obj = gap + obj_description + ' hat als ' + rel.text + ' ' + pred['VAL'][0] + '.'\n",
        "    gap_val = upper_first(pred['OBJ'][0]) + ' hat als ' + rel.text + ' ' + gap + val_description + '.'\n",
        "  mc_obj = equivalents[0] + pred['OBJ'] if equivalents[0] else []\n",
        "  mc_val = equivalents[1] + pred['VAL'] if equivalents[1] else []\n",
        "  random.shuffle(mc_obj)\n",
        "  random.shuffle(mc_val)\n",
        "  mc_obj = ' '.join([mc[i] + mc_obj[i] for i in range(len(mc_obj))])\n",
        "  mc_val = ' '.join([mc[i] + mc_val[i] for i in range(len(mc_val))])\n",
        "  return (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val)\n",
        "\n",
        "def apply_rule3_extended(pred, rel, obj_cat, val_cat):\n",
        "  \"\"\"\n",
        "   #3 <Object> wird/ist/wurde/hat <Relation (!VVPP)> <Value> <Relation (VVPP)>.\n",
        "\t  --> Am 11.März 1952 wurde Douglas Adams geboren.\n",
        "\t  --> Kurt Cobain ist am 5. April 1994 gestorben.\n",
        "\t  --> Kopfschmerzen wird mit Ibuprofen behandelt.\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :return true_stmt: str, statement which is true\n",
        "  :return false_stmt1: str, statement with a wrong object\n",
        "  :return false_stmt2: str, statement with a wrong value\n",
        "  :return gap_obj: str, statement with object blanked out\n",
        "  :return gap_val: str, statement with value blanked out\n",
        "  :return mc_obj: array_like, list of possible object-replacements\n",
        "  :return mc_val: array_like, list of possible value-replacements\n",
        "  \"\"\"\n",
        "  equivalents = get_equivalents(pred, obj_cat, val_cat)\n",
        "  obj_description = ' (' + '/'.join([word for word in obj_cat[1:]]) + ') ' if len(obj_cat) > 1 else ''\n",
        "  val_description = ' (' + '/'.join([word for word in val_cat[1:]]) + ') ' if len(val_cat) > 1 else ''\n",
        "  rel_head = ' '.join([token.text for token in rel if token.tag_ != 'VVPP'])\n",
        "  rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'VVPP'])\n",
        "  rel_head = rel_head + ' ' if len(rel_head) > 0 else ''\n",
        "  auxiliary = auxiliary_dict[rel_tail] if rel_tail in auxiliary_dict else 'wird/wurde/hat/ist '\n",
        "\n",
        "  true_stmt = upper_first(pred['OBJ'][0]) + ' ' + auxiliary + rel_head + pred['VAL'][0] + ' ' + rel_tail + '.'\n",
        "  false_stmt1 = upper_first(equivalents[0][0]) +  ' ' + auxiliary + rel_head + pred['VAL'][0] + ' ' + rel_tail + '.' if equivalents[0] else None\n",
        "  false_stmt2 = upper_first(pred['OBJ'][0]) +  ' ' + auxiliary + rel_head + equivalents[1][0] + ' ' + rel_tail + '.' if equivalents[1] else None\n",
        "  gap_obj = gap + obj_description + ' ' + auxiliary + rel_head + pred['VAL'][0] + ' ' + rel_tail + '.'\n",
        "  gap_val = upper_first(pred['OBJ'][0]) + ' ' + auxiliary + rel_head + gap + val_description + ' ' + rel_tail + '.'\n",
        "  mc_obj = equivalents[0] + pred['OBJ'] if equivalents[0] else []\n",
        "  mc_val = equivalents[1] + pred['VAL'] if equivalents[1] else []\n",
        "  random.shuffle(mc_obj)\n",
        "  random.shuffle(mc_val)\n",
        "  mc_obj = ' '.join([mc[i] + mc_obj[i] for i in range(len(mc_obj))])\n",
        "  mc_val = ' '.join([mc[i] + mc_val[i] for i in range(len(mc_val))])\n",
        "  return (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val)\n",
        "\n",
        "def apply_rule4_extended(pred, rel, obj_cat, val_cat, is_template_a):\n",
        "  \"\"\"\n",
        "  #4a <Object> <Relation V*FIN> <Value> <Relation (PTKVZ)>.\n",
        "\t  --> \"Harry Potter und der Stein der Weisen\" schrieb Joanne K. Rowling nieder.\n",
        "\t\n",
        "\t#4b <Object> <Relation V*FIN> <Value>?  \n",
        "    --> \"Harry Potter und der Stein der Weisen\" schrieb Joanne K. Rowling.\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :param is_template_a: bool\n",
        "  :return true_stmt: str, statement which is true\n",
        "  :return false_stmt1: str, statement with a wrong object\n",
        "  :return false_stmt2: str, statement with a wrong value\n",
        "  :return gap_obj: str, statement with object blanked out\n",
        "  :return gap_val: str, statement with value blanked out\n",
        "  :return mc_obj: array_like, list of possible object-replacements\n",
        "  :return mc_val: array_like, list of possible value-replacements\n",
        "  \"\"\"  \n",
        "  equivalents = get_equivalents(pred, obj_cat, val_cat)\n",
        "  obj_description = ' (' + '/'.join([word for word in obj_cat[1:]]) + ') ' if len(obj_cat) > 1 else ''\n",
        "  val_description = ' (' + '/'.join([word for word in val_cat[1:]]) + ') ' if len(val_cat) > 1 else ''\n",
        "  if is_template_a:\n",
        "    rel_head = ' '.join([token.text for token in rel if token.tag_ != 'PTKVZ'])\n",
        "    rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'PTKVZ'])\n",
        "\n",
        "    true_stmt = upper_first(pred['OBJ'][0]) + ' ' + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '.'\n",
        "    false_stmt1 = upper_first(equivalents[0][0]) + ' ' + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '.' if equivalents[0] else None\n",
        "    false_stmt2 = upper_first(pred['OBJ'][0]) + ' ' + rel_head + ' ' + equivalents[1][0] + ' ' + rel_tail + '.' if equivalents[1] else None\n",
        "    gap_obj = gap + obj_description + ' ' + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '.'\n",
        "    gap_val = upper_first(pred['OBJ'][0]) + ' ' + rel_head + ' ' + gap + val_description + ' ' + rel_tail + '.'\n",
        "  else:\n",
        "    true_stmt = upper_first(pred['OBJ'][0]) + ' ' + rel.text + ' ' + pred['VAL'][0] + '.'\n",
        "    false_stmt1 = upper_first(equivalents[0][0]) + ' ' + rel.text + ' ' + pred['VAL'][0] + '.' if equivalents[0] else None\n",
        "    false_stmt2 = upper_first(pred['OBJ'][0]) + ' ' + rel.text + ' ' + equivalents[1][0] + '.' if equivalents[1] else None\n",
        "    gap_obj = gap + obj_description + ' ' + rel.text + ' ' + pred['VAL'][0] + '.'\n",
        "    gap_val = upper_first(pred['OBJ'][0]) + ' ' + rel.text + ' ' + gap + val_description + '.'\n",
        "  mc_obj = equivalents[0] + pred['OBJ'] if equivalents[0] else []\n",
        "  mc_val = equivalents[1] + pred['VAL'] if equivalents[1] else []\n",
        "  random.shuffle(mc_obj)\n",
        "  random.shuffle(mc_val)\n",
        "  mc_obj = ' '.join([mc[i] + mc_obj[i] for i in range(len(mc_obj))])\n",
        "  mc_val = ' '.join([mc[i] + mc_val[i] for i in range(len(mc_val))])\n",
        "  return (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val)\n",
        "\n",
        "def apply_rule5_extended(pred, rel, obj_cat, val_cat, is_template_a):\n",
        "  \"\"\"\n",
        "  Clean up-rule. Verb is most probably predicted falsely!\n",
        "  #5a <Object> <Relation (!PTKVZ)> <Value> <Relation (PTKVZ)>.\n",
        "\t#5b <Object> <Relation> <Value>.\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :param is_template_a: bool\n",
        "  :return true_stmt: str, statement which is true\n",
        "  :return false_stmt1: str, statement with a wrong object\n",
        "  :return false_stmt2: str, statement with a wrong value\n",
        "  :return gap_obj: str, statement with object blanked out\n",
        "  :return gap_val: str, statement with value blanked out\n",
        "  :return mc_obj: array_like, list of possible object-replacements\n",
        "  :return mc_val: array_like, list of possible value-replacements\n",
        "  \"\"\"\n",
        "  equivalents = get_equivalents(pred, obj_cat, val_cat)\n",
        "  obj_description = ' (' + '/'.join([word for word in obj_cat[1:]]) + ') ' if len(obj_cat) > 1 else ''\n",
        "  val_description = ' (' + '/'.join([word for word in val_cat[1:]]) + ') ' if len(val_cat) > 1 else ''\n",
        "  if is_template_a:\n",
        "    rel_head = ' '.join([token.text for token in rel if token.tag_ != 'PTKVZ'])\n",
        "    rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'PTKVZ'])\n",
        "\n",
        "    true_stmt = upper_first(pred['OBJ'][0]) + ' ' + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '.'\n",
        "    false_stmt1 = upper_first(equivalents[0][0]) + ' ' + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '.' if equivalents[0] else None\n",
        "    false_stmt2 = upper_first(pred['OBJ'][0]) + ' ' + rel_head + ' ' + equivalents[1][0] + ' ' + rel_tail + '.' if equivalents[1] else None\n",
        "    gap_obj = gap + obj_description + ' ' + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '.'\n",
        "    gap_val = upper_first(pred['OBJ'][0]) + ' ' + rel_head + ' ' + gap + val_description + ' ' + rel_tail + '.'\n",
        "  else:\n",
        "    true_stmt = upper_first(pred['OBJ'][0]) + ' ' + rel.text + ' ' + pred['VAL'][0] + '.'\n",
        "    false_stmt1 = upper_first(equivalents[0][0]) + ' ' + rel.text + ' ' + pred['VAL'][0] + '.' if equivalents[0] else None\n",
        "    false_stmt2 = upper_first(pred['OBJ'][0]) + ' ' + rel.text + ' ' + equivalents[1][0] + '.' if equivalents[1] else None\n",
        "    gap_obj = gap + obj_description + ' ' + rel.text + ' ' + pred['VAL'][0] + '.'\n",
        "    gap_val = upper_first(pred['OBJ'][0]) + ' ' + rel.text + ' ' + gap + val_description + '.'\n",
        "  mc_obj = equivalents[0] + pred['OBJ'] if equivalents[0] else []\n",
        "  mc_val = equivalents[1] + pred['VAL'] if equivalents[1] else []\n",
        "  random.shuffle(mc_obj)\n",
        "  random.shuffle(mc_val)\n",
        "  mc_obj = ' '.join([mc[i] + mc_obj[i] for i in range(len(mc_obj))])\n",
        "  mc_val = ' '.join([mc[i] + mc_val[i] for i in range(len(mc_val))])\n",
        "  return (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYBasAW1JHtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "auxiliary_dict = {'geboren':'wurde ','gestorben':'ist ','geschrieben':'wurde/hat ','gegründet':'wurde/hat ', 'getauft':'wurde/hat '}\n",
        "locations = ['Metropole', 'Bundesland','County', 'Land','Kanton','Dorf','Gemeinde']\n",
        "\n",
        "def lookup_gender(input):\n",
        "  \"\"\"Helper method to lookup gender of given input-word(s). \n",
        "  :param input: str\n",
        "  :return: str, \n",
        "    m if masculin\n",
        "    f if feminine\n",
        "    n if neutrum\n",
        "    UNK if unknown\"\"\"\n",
        "    \n",
        "  word = input.replace('ö', 'oe')\n",
        "  word = word.replace('ä', 'ae')\n",
        "  word = word.replace('ü', 'ue')\n",
        "  try:\n",
        "    w = duden.get(word.split(' ')[-1])\n",
        "    suffixes = {'der':'m', 'die':'f', 'das':'n'}\n",
        "    if w and w.article:\n",
        "      return suffixes[w.article]\n",
        "    else:\n",
        "      return 'UNK'\n",
        "  except:\n",
        "    return patt.gender(input) if patt.gender(input) else 'UNK'\n",
        "\n",
        "def get_question_word(obj_cat, val_cat):\n",
        "  \"\"\"Generate question word based on category and gender of given object.\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :return: str, question word and optional description of object\"\"\"\n",
        "\n",
        "  if 'Mensch' in obj_cat:\n",
        "    question_word = 'Wer '\n",
        "  elif 'Familienname' in obj_cat or 'männlicher Vorname' in obj_cat or 'weiblicher Vorname' in obj_cat:\n",
        "    question_word = 'Wer '\n",
        "    obj_cat = np.insert(obj_cat, 0, 'Mensch')\n",
        "  elif ('Mensch' in val_cat and obj_cat[0].endswith('tadt')) or ('Mensch' in val_cat and obj_cat[0].endswith('taat')) or ('Mensch' in val_cat and obj_cat[0] in locations):\n",
        "    question_word = 'Wo '\n",
        "    obj_cat = np.insert(obj_cat, 0, 'Ort')\n",
        "  elif 'Zeitpunkt' in obj_cat or 'Zeitpunkt innerhalb eines wiederkehrenden Zeitrahmens' in obj_cat:\n",
        "    question_word = 'Wann '\n",
        "  elif 'Ding' in obj_cat:\n",
        "    question_word = 'Wer oder was ' \n",
        "  else:\n",
        "    gender = lookup_gender(obj_cat[0])\n",
        "    suffixes = {'m':'r ', 'f':' ', 'n':'s ', 'UNK':'(-/r/s) '}\n",
        "    question_word = 'Welche' + suffixes[gender] + obj_cat[0] + ' '\n",
        "  description = '(' + '/'.join([word for word in obj_cat[1:]]) + ') ' if len(obj_cat) > 1 else ''\n",
        "  return question_word + description\n",
        "\n",
        "def apply_rule1(pred, rel, obj_cat, val_cat):\n",
        "  \"\"\"\n",
        "  #1 Welche(r/s) <Object-Type> hat ein(e/en) <Relation (NN/NE)> von <Value (Number)>? \n",
        "\t  --> Welcher Berg hat eine Höhe von 8848?\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :return: str, generated question\n",
        "  \"\"\"\n",
        "  noun = [token.text for token in rel if token.tag_ == 'NN' or token.tag_ == 'NE'][0]\n",
        "  question_word = get_question_word(obj_cat, val_cat)\n",
        "  gender = lookup_gender(noun)\n",
        "  suffixes = {'m':'en ', 'f':'e ', 'n':' ', 'UNK':'/e(n) '}\n",
        "  question = question_word + 'hat ein' + suffixes[gender] + rel.text + ' von ' + pred['VAL'][0] + '?'\n",
        "  return question\n",
        "\n",
        "def apply_rule2(pred, rel, obj_cat, val_cat, is_template_a):\n",
        "  \"\"\"\n",
        "  #2a Welche(r/s) <Object-Type> ist <Relation (NN/NE)> <Relation (APPR/APPRART/PTKVZ)> <Value>?\n",
        "\t  --> Welcher Mensch ist (der) Vater von Douglas Adams?\n",
        "\t  --> Wer ist (der) Vater von Douglas Adams?\n",
        "  #2b Welche(r/s) <Object-Type> hat als <Relation (NN/NE)> <Value>? \n",
        "\t  --> Welches Werk hat als Komponist Wolfgang Amadeus Mozart?\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :param is_template_a: bool\n",
        "  :return: str, generated question\n",
        "  \"\"\"\n",
        "  question_word = get_question_word(obj_cat, val_cat)\n",
        "  if is_template_a:\n",
        "    rel_head = ' '.join([token.text for token in rel if token.tag_ == 'NN' or token.tag_ == 'NE'])\n",
        "    rel_head = rel_head + ' ' if len(rel_head) > 0 else ''\n",
        "    rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'PTKVZ' or token.tag_=='APPR' or token.tag_=='APPRART'])\n",
        "    return question_word + 'ist ' + rel_head + rel_tail + ' ' + pred['VAL'][0] + '?'\n",
        "  else:\n",
        "    return question_word + 'hat als ' + rel.text + ' ' + pred['VAL'][0] + '?'\n",
        "\n",
        "def apply_rule3(pred, rel, obj_cat, val_cat):\n",
        "  \"\"\"\n",
        "   #3 Welche(r/s) <Object-Type> wird/ist/wurde/hat <Relation (!VVPP)> <Value> <Relation (VVPP)>?\n",
        "\t  --> Welcher Zeitpunkt wurde Douglas Adams geboren?\n",
        "\t  --> Wann wurde Douglas Adams geboren?\n",
        "\t  --> Wer ist am 5. April 1994 gestorben?\n",
        "\t  --> Welche Krankheit wird mit Ibuprofen behandelt?\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :return: str, generated question\n",
        "  \"\"\"\n",
        "  question_word = get_question_word(obj_cat, val_cat)\n",
        "  rel_head = ' '.join([token.text for token in rel if token.tag_ != 'VVPP'])\n",
        "  rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'VVPP'])\n",
        "  rel_head = rel_head + ' ' if len(rel_head) > 0 else ''\n",
        "  auxiliary = auxiliary_dict[rel_tail] if rel_tail in auxiliary_dict else 'wird/wurde/hat/ist '\n",
        "  return question_word + auxiliary + rel_head + pred['VAL'][0] + ' ' + rel_tail + '?'\n",
        "\n",
        "def apply_rule4(pred, rel, obj_cat, val_cat, is_template_a):\n",
        "  \"\"\"\n",
        "  #4a Welche(r/s) <Object-Type> <Relation V*FIN> <Value> <Relation (PTKVZ)>? \n",
        "\t  --> Welches Buch schrieb Joanne K. Rowling nieder?\n",
        "\t\n",
        "\t#4b Welche(r/s) <Object-Type> <Relation V*FIN> <Value>?  \n",
        "    --> Welches Buch schrieb Joanne K. Rowling?\n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :param is_template_a: bool\n",
        "  :return: str, generated question\n",
        "  \"\"\"\n",
        "  question_word = get_question_word(obj_cat, val_cat)\n",
        "  if is_template_a:\n",
        "    rel_head = ' '.join([token.text for token in rel if token.tag_ != 'PTKVZ'])\n",
        "    rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'PTKVZ'])\n",
        "    return question_word + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '?'\n",
        "  else:\n",
        "    return question_word + rel.text + ' ' + pred['VAL'][0] + '?'\n",
        "\n",
        "\n",
        "def apply_rule5(pred, rel, obj_cat, val_cat, is_template_a):\n",
        "  \"\"\"\n",
        "  Clean up-rule. Verb is most probably predicted falsely!\n",
        "  #5a Welche(r/s) <Object-Type> <Relation (!PTKVZ)> <Value> <Relation (PTKVZ)>? \n",
        "\t#5b Welche(r/s) <Object-Type> <Relation> <Value>? \n",
        "\n",
        "  :param pred: dict, predicted triplet\n",
        "  :param rel: spacy token\n",
        "  :param obj_cat: array_like, list of object's types\n",
        "  :param val_cat: array_like, list of value's types\n",
        "  :param is_template_a: bool\n",
        "  :return: str, generated question\n",
        "  \"\"\"\n",
        "  question_word = get_question_word(obj_cat, val_cat)\n",
        "  if is_template_a:\n",
        "    rel_head = ' '.join([token.text for token in rel if token.tag_ != 'PTKVZ'])\n",
        "    rel_tail = ' '.join([token.text for token in rel if token.tag_ == 'PTKVZ'])\n",
        "    return question_word + rel_head + ' ' + pred['VAL'][0] + ' ' + rel_tail + '?'\n",
        "  else:\n",
        "    return question_word + rel.text + ' ' + pred['VAL'][0] + '?'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPU4uvmnD5GZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "def generate_questions(predictions):\n",
        "  \"\"\"Method that generates questions out of the given predicted triplets.\n",
        "  :param predictions: array_like,\n",
        "      list of triplets-dictionary of form \n",
        "      {'CONTEXT': [], 'OBJ': [], 'REL': [], 'VAL': []}\n",
        "  :return questions: array_like,\n",
        "      list of generated questions with context as answer\n",
        "  :return questions_extended: array_like,\n",
        "      list of more complex question forms \n",
        "      (multiple choice, True/False, Fill-the-gap)\n",
        "  :return complex_objects: dict,\n",
        "      dictionary containing object and substitutions as value \n",
        "      e.g. {\"Christopher Douglas Adams\" : \"Vater von Douglas Adams}\n",
        "    \"\"\"\n",
        "  questions = []\n",
        "  questions_extended = []\n",
        "  complex_objects = {}\n",
        "  for i in range(len(predictions)):\n",
        "    obj_cat = lookup_category(predictions[i]['OBJ'][0])\n",
        "    val_cat = lookup_category(predictions[i]['VAL'][0])\n",
        "    #print(predictions[i]['OBJ'], predictions[i]['REL'], predictions[i]['VAL'])\n",
        "    rel = nlp(predictions[i]['REL'][0])\n",
        "    rel_tags = [token.tag_ for token in rel]\n",
        "    rel_tokens = [token.text for token in rel]\n",
        "    rel_tags = ['XY' if rel_tags[i] in ['NN', 'NE'] and rel_tokens[i].islower() else rel_tags[i] for i in range(len(rel_tags))  ]\n",
        "    #print(rel_tokens, rel_tags)\n",
        "    if ('Zeitpunkt' in val_cat and 'am' not in predictions[i]['VAL'][0] and 'NN' not in rel_tags):\n",
        "      value = 'am ' + predictions[i]['VAL'][0]\n",
        "      predictions[i]['VAL'] = [value]\n",
        "      if 'am' in rel_tokens:\n",
        "        rel_tokens.remove('am')\n",
        "        relation = ' '.join([t for t in rel_tokens])\n",
        "        predictions[i]['REL'] = [relation]\n",
        "        rel = nlp(predictions[i]['REL'][0])\n",
        "    if ('NN' in rel_tags or 'NE' in rel_tags) and ('Zahl' in val_cat):\n",
        "      #print(1)\n",
        "      question = apply_rule1(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      questions.append((question, predictions[i]['CONTEXT'][0]))\n",
        "      (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val) = apply_rule1_extended(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      if true_stmt and false_stmt1 and false_stmt2:\n",
        "        questions_extended.append((true_stmt, false_stmt1, false_stmt2, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_obj:\n",
        "        questions_extended.append((gap_obj, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_val:\n",
        "        questions_extended.append((gap_val, mc_val, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if mc_obj:\n",
        "        questions_extended.append((question, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "    elif 'NN' in rel_tags or 'NE' in rel_tags:\n",
        "      is_template_a = 'PTKVZ' in rel_tags or 'APPR' in rel_tags or 'APPRART' in rel_tags\n",
        "      #print(2, is_template_a)\n",
        "      question = apply_rule2(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      questions.append((question, predictions[i]['CONTEXT'][0]))\n",
        "      (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val) = apply_rule2_extended(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      if true_stmt and false_stmt1 and false_stmt2:\n",
        "        questions_extended.append((true_stmt, false_stmt1, false_stmt2, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_obj:\n",
        "        questions_extended.append((gap_obj, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_val:\n",
        "        questions_extended.append((gap_val, mc_val, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if mc_obj:\n",
        "        questions_extended.append((question, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      #if is_template_a:\n",
        "      aliases = [] if predictions[i]['OBJ'][0] not in complex_objects else complex_objects[predictions[i]['OBJ'][0]]\n",
        "      aliases.append(predictions[i]['REL'][0] + ' ' + predictions[i]['VAL'][0])\n",
        "      complex_objects[predictions[i]['OBJ'][0]] = list(set(aliases))\n",
        "    elif 'VVPP' in rel_tags:\n",
        "      is_template_a = 'PTKVZ' in rel_tags or 'APPR' in rel_tags or 'APPRART' in rel_tags\n",
        "      #print(3, is_template_a)\n",
        "      question = apply_rule3(predictions[i], rel, obj_cat, val_cat)\n",
        "      questions.append((question, predictions[i]['CONTEXT'][0]))\n",
        "      (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val) = apply_rule3_extended(predictions[i], rel, obj_cat, val_cat)\n",
        "      if true_stmt and false_stmt1 and false_stmt2:\n",
        "        questions_extended.append((true_stmt, false_stmt1, false_stmt2, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_obj:\n",
        "        questions_extended.append((gap_obj, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_val:\n",
        "        questions_extended.append((gap_val, mc_val, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if mc_obj:\n",
        "        questions_extended.append((question, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "    elif 'VVFIN' in rel_tags or 'VAFIN' in rel_tags:\n",
        "      is_template_a = 'PTKVZ' in rel_tags\n",
        "      #print(4, is_template_a)\n",
        "      question = apply_rule4(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      questions.append((question, predictions[i]['CONTEXT'][0]))\n",
        "      (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val) = apply_rule4_extended(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      if true_stmt and false_stmt1 and false_stmt2:\n",
        "        questions_extended.append((true_stmt, false_stmt1, false_stmt2, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_obj:\n",
        "        questions_extended.append((gap_obj, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_val:\n",
        "        questions_extended.append((gap_val, mc_val, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if mc_obj:\n",
        "        questions_extended.append((question, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "    else:\n",
        "      is_template_a = 'PTKVZ' in rel_tags\n",
        "      #print(5, is_template_a)\n",
        "      question = apply_rule5(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      questions.append((question, predictions[i]['CONTEXT'][0]))\n",
        "      (true_stmt, false_stmt1, false_stmt2, gap_obj, gap_val, mc_obj, mc_val) = apply_rule5_extended(predictions[i], rel, obj_cat, val_cat, is_template_a)\n",
        "      if true_stmt and false_stmt1 and false_stmt2:\n",
        "        questions_extended.append((true_stmt + '\\nTRUE', false_stmt1 + '\\nFALSE', false_stmt2 + '\\nFALSE', predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_obj:\n",
        "        questions_extended.append((gap_obj, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if gap_val:\n",
        "        questions_extended.append((gap_val, mc_val, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "      if mc_obj:\n",
        "        questions_extended.append((question, mc_obj, predictions[i]['CONTEXT'][0]))\n",
        "        print(questions_extended[-1])\n",
        "    print(questions)\n",
        "  return [questions, questions_extended, complex_objects]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXXdwluUQoqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Frageset erstellen { display-mode: \"form\" }\n",
        "#@markdown Generate question-set\n",
        "def generate_question_set(predictions):\n",
        "  \"\"\"Wrapper around generate_questions with additional option \n",
        "    to generate complex questions.\n",
        "    :param predictions: array_like,\n",
        "      list of triplets-dictionary of form \n",
        "      {'CONTEXT': [], 'OBJ': [], 'REL': [], 'VAL': []}\n",
        "    :return questions: array_like,\n",
        "        list of generated questions with context as answer\n",
        "    :return questions_extended: array_like,\n",
        "        list of more complex question forms \n",
        "        (multiple choice, True/False, Fill-the-gap)\n",
        "    :return complex_obj_questions: array_like,\n",
        "        list of generated questions with complex objects \"\"\"\n",
        "  questions, questions_extended, complex_objects = generate_questions(predictions)\n",
        "  complex_triplets = []\n",
        "  for triplet in predictions:\n",
        "    if triplet['OBJ'][0] in complex_objects and triplet['REL'][0] + ' ' + triplet['VAL'][0] not in complex_objects[triplet['OBJ'][0]]:\n",
        "      for obj in complex_objects[triplet['OBJ'][0]]:\n",
        "        value = triplet['VAL'][0].replace('am ', '')\n",
        "        complex_triplets.append({'OBJ':[value],'REL':triplet['REL'],'VAL':[obj], 'CONTEXT': triplet['CONTEXT']})\n",
        "  complex_obj_questions, b, c = generate_questions(complex_triplets)\n",
        "  return [questions, questions_extended, complex_obj_questions]\n",
        "\n",
        "baseline_questions, baseline_questions_extended, baseline_complex_obj_questions = generate_question_set(baseline_predictions)\n",
        "print('\\n')\n",
        "questions, questions_extended, complex_obj_questions = generate_question_set(predictions)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJvGhi_g2Z95",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Fragen herunterladen (falls gewünscht)\n",
        "#@markdown Download questions (if desired)\n",
        "if 'download_questions' in globals() and download_questions:\n",
        "  with open('baseline-question-set.txt', 'wt') as outfile:\n",
        "    if baseline_questions:\n",
        "      outfile.write('QUESTIONS\\n')\n",
        "      [outfile.write(q + '\\n' + c + '\\n') for q,c in baseline_questions]\n",
        "    if baseline_questions_extended:\n",
        "      outfile.write('\\nEXTENDED QUESTIONS\\n')\n",
        "      for question in baseline_questions_extended:\n",
        "        for q_item in question:\n",
        "          if q_item:\n",
        "            outfile.write(q_item + '\\n')\n",
        "        outfile.write('\\n')\n",
        "    if baseline_complex_obj_questions:\n",
        "      outfile.write('\\nCOMPLEX QUESTIONS\\n')\n",
        "      [outfile.write(q + '\\n' + c + '\\n') for q,c in baseline_complex_obj_questions]\n",
        "  #files.download('baseline-question-set.txt') \n",
        "  with open('predictor-question-set.txt', 'wt') as outfile:\n",
        "    if questions:\n",
        "      outfile.write('QUESTIONS\\n')\n",
        "      [outfile.write(q + '\\n' + c + '\\n') for q,c in questions]\n",
        "    if questions_extended:\n",
        "      outfile.write('\\nEXTENDED QUESTIONS\\n')\n",
        "      for question in questions_extended:\n",
        "        for q_item in question:\n",
        "          if q_item:\n",
        "            outfile.write(q_item + '\\n')\n",
        "        outfile.write('\\n')\n",
        "    if complex_obj_questions:\n",
        "      outfile.write('\\nCOMPLEX QUESTIONS\\n')\n",
        "      [outfile.write(q + '\\n' + c + '\\n') for q, c in complex_obj_questions]\n",
        "  #files.download('predictor-question-set.txt') \n",
        "else:\n",
        "  if baseline_questions:\n",
        "      print('QUESTIONS')\n",
        "      [print(q + '\\n' + c + '\\n') for q,c in baseline_questions]\n",
        "  if baseline_questions_extended:\n",
        "    print('EXTENDED QUESTIONS')\n",
        "    for question in baseline_questions_extended:\n",
        "      for q_item in question:\n",
        "        if q_item:\n",
        "          print(q_item)\n",
        "      print('\\n')\n",
        "  if baseline_complex_obj_questions:\n",
        "    print('\\nCOMPLEX QUESTIONS\\n')\n",
        "    [print(q + '\\n' + c + '\\n') for q,c in baseline_complex_obj_questions]\n",
        "  #files.download('baseline-question-set.txt') \n",
        "  with open('predictor-question-set.txt', 'wt') as outfile:\n",
        "    if questions:\n",
        "      print('QUESTIONS\\n')\n",
        "      [print(q + '\\n' + c + '\\n') for q,c in questions]\n",
        "    if questions_extended:\n",
        "      print('\\nEXTENDED QUESTIONS\\n')\n",
        "      for question in questions_extended:\n",
        "        for q_item in question:\n",
        "          if q_item:\n",
        "            print(q_item + '\\n')\n",
        "        print('\\n')\n",
        "    if complex_obj_questions:\n",
        "      print('\\nCOMPLEX QUESTIONS\\n')\n",
        "      [print(q + '\\n' + c + '\\n') for q, c in complex_obj_questions]\n",
        "if 'download_questions' in globals() and download_questions:\n",
        "  files.download('baseline-question-set.txt')\n",
        "  files.download('predictor-question-set.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUMnivOxn5a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "!rm baseline-question-set.txt\n",
        "!rm predictor-question-set.txt\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}